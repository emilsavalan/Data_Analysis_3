{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 449,
      "id": "458eb6de",
      "metadata": {
        "id": "458eb6de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4165c534-4130-402b-ff79-780cd2fb86c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import geopy.distance\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_rows', 10000)\n",
        "pd.options.display.max_rows = 10000\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset for December**"
      ],
      "metadata": {
        "id": "zwdoNekcLyrf"
      },
      "id": "zwdoNekcLyrf"
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "id": "ba906658",
      "metadata": {
        "id": "ba906658"
      },
      "outputs": [],
      "source": [
        "# data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/PS2/data/december/listings.csv\")\n",
        "data = pd.read_csv(\"data/december/listings.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Droping unnecessary columns. Some of them has a lot NaNs. Some of them are just meaningless for prediction. Or is similar to other feature**"
      ],
      "metadata": {
        "id": "G3uR6ziRL7r2"
      },
      "id": "G3uR6ziRL7r2"
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "id": "81e9d60c",
      "metadata": {
        "id": "81e9d60c"
      },
      "outputs": [],
      "source": [
        "drops = [\"calendar_updated\", \"neighbourhood\", \"host_response_time\", \"host_response_rate\",\n",
        "         \"host_neighbourhood\", \"has_availability\",\"host_verifications\", \"host_has_profile_pic\", \"host_total_listings_count\",\n",
        "    \"license\",\n",
        "    \"neighbourhood_group_cleansed\",\n",
        "    \"bathrooms\",\n",
        "    \"host_thumbnail_url\",\n",
        "    \"host_picture_url\",\n",
        "    \"listing_url\",\n",
        "    \"picture_url\",\n",
        "    \"host_url\",\n",
        "    \"last_scraped\",\n",
        "    \"description\", \"calendar_last_scraped\",\n",
        "    \"neighborhood_overview\",\n",
        "    \"host_about\",\n",
        "    \"name\", \"host_location\", \"host_id\", \"host_name\"]\n",
        "data.drop(columns=drops, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting percentage values to float**"
      ],
      "metadata": {
        "id": "CU-cObx1MYO6"
      },
      "id": "CU-cObx1MYO6"
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "id": "6345d669",
      "metadata": {
        "id": "6345d669"
      },
      "outputs": [],
      "source": [
        "data['host_acceptance_rate'] = data['host_acceptance_rate'].str.rstrip(\"%\").astype(float)/100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning the target (price)**"
      ],
      "metadata": {
        "id": "s2Xajqz0MkrZ"
      },
      "id": "s2Xajqz0MkrZ"
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "id": "d1a76454",
      "metadata": {
        "id": "d1a76454"
      },
      "outputs": [],
      "source": [
        "data['price'] = data['price'].str.replace(r'[$,]', '').astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking for the outliers. Just 2. Seems OK**"
      ],
      "metadata": {
        "id": "A4CQGtyMMp7X"
      },
      "id": "A4CQGtyMMp7X"
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "id": "ce339bb8",
      "metadata": {
        "scrolled": true,
        "id": "ce339bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b1b293-a71e-411a-e97c-700d343adad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "798     26696.0\n",
              "1144    71536.0\n",
              "Name: price, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 454
        }
      ],
      "source": [
        "# prices == 0\n",
        "# prices >25k\n",
        "data[data[\"price\"]>25000][\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting to binary variables**"
      ],
      "metadata": {
        "id": "51WJrK0hMwn_"
      },
      "id": "51WJrK0hMwn_"
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "id": "a4200cb6",
      "metadata": {
        "id": "a4200cb6"
      },
      "outputs": [],
      "source": [
        "data['host_is_superhost'] = data['host_is_superhost'].apply(lambda x: 1 if x == 't' else (0 if x == 'f' else x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['host_identity_verified'] = data['host_identity_verified'].apply(lambda x: 1 if x == 't' else (0 if x == 'f' else x))"
      ],
      "metadata": {
        "id": "ABMhL1pzjMcd"
      },
      "id": "ABMhL1pzjMcd",
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "id": "d6ca4d49",
      "metadata": {
        "id": "d6ca4d49"
      },
      "outputs": [],
      "source": [
        "data[\"host_identity_verified\"].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "id": "33cd6e90",
      "metadata": {
        "id": "33cd6e90"
      },
      "outputs": [],
      "source": [
        "data['instant_bookable'] = data['instant_bookable'].apply(lambda x: 1 if x == 't' else (0 if x == 'f' else x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning the string in amenities feature**"
      ],
      "metadata": {
        "id": "Z-_avc1dM3sN"
      },
      "id": "Z-_avc1dM3sN"
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "id": "c07e11da",
      "metadata": {
        "id": "c07e11da"
      },
      "outputs": [],
      "source": [
        "data['amenities'] = data['amenities'].apply(lambda x: re.sub(r'\\\\u\\w{4}', '', re.sub(r'\\\\', '', re.sub(r'\\[', '',  re.sub(r'\\]', '', re.sub(r'\"', '', re.sub(r',', '', x)))))  ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collecting all words in a list for each row**"
      ],
      "metadata": {
        "id": "jUN_Pz1JM9-U"
      },
      "id": "jUN_Pz1JM9-U"
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "id": "0b84c106",
      "metadata": {
        "id": "0b84c106"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "data['amenities'].apply(lambda x:  words.append(x.split(\" \")))\n",
        "flat_list = []\n",
        "for sub_list in words:\n",
        "    for item in sub_list:\n",
        "        flat_list.append(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Droping meaningless and less frequent words. Then choosing the most frequent ones**"
      ],
      "metadata": {
        "id": "lBaYIRLPNHDY"
      },
      "id": "lBaYIRLPNHDY"
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "id": "3916e9ad",
      "metadata": {
        "id": "3916e9ad"
      },
      "outputs": [],
      "source": [
        "ab = pd.DataFrame(pd.Series(flat_list).value_counts())\n",
        "ab.columns = [\"counts\"]\n",
        "ab = ab[ab[\"counts\"]>600]\n",
        "ba = ab.transpose()\n",
        "ba = ba.drop(columns=[\"and\", \"allowed\", \"Private\", \"Essentials\",\"silverware\",\\\n",
        "                      \"Long\", \"Hair\", \"stays\", \"term\", \"Bed\", \"Shampoo\", \"Cooking\", \"basics\", \"u2013\",\\\n",
        "                      \"Paid\", \"Carbon\", \"monoxide\", \"maker\"\n",
        "                     ], axis=1)\n",
        "findd = ba.columns[:18]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating dummies**"
      ],
      "metadata": {
        "id": "xnASUH7ENViJ"
      },
      "id": "xnASUH7ENViJ"
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "id": "0000a76b",
      "metadata": {
        "id": "0000a76b"
      },
      "outputs": [],
      "source": [
        "for ind, row in data.iterrows():\n",
        "    for i in list(set(row[\"amenities\"].split(\" \")) & set(findd)):\n",
        "        data.at[ind, i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "id": "c1804d34",
      "metadata": {
        "id": "c1804d34"
      },
      "outputs": [],
      "source": [
        "for i in findd:\n",
        "    data[i].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating dummies for property type**"
      ],
      "metadata": {
        "id": "G1cZeipzNaGe"
      },
      "id": "G1cZeipzNaGe"
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "id": "4143018c",
      "metadata": {
        "scrolled": false,
        "id": "4143018c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5048f7b-c051-4731-eb35-afb4caef8f31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Entire rental unit                   2384\n",
              "Entire condo                         1284\n",
              "Private room in rental unit           520\n",
              "Entire home                           432\n",
              "Private room in bed and breakfast     294\n",
              "Entire townhouse                      213\n",
              "Entire loft                           186\n",
              "Private room in condo                 135\n",
              "Houseboat                             132\n",
              "Private room in home                  130\n",
              "Room in boutique hotel                122\n",
              "Room in hotel                         117\n",
              "Private room in houseboat             102\n",
              "Private room in guest suite            99\n",
              "Private room in townhouse              91\n",
              "Name: property_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 464
        }
      ],
      "source": [
        "data[\"property_type\"].value_counts().head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "id": "3ad1cea0",
      "metadata": {
        "id": "3ad1cea0"
      },
      "outputs": [],
      "source": [
        "for_ = ['Private room in houseboat', 'Boat', 'Entire rental unit',\n",
        "        'Private room in bed and breakfast', 'Entire villa','Private room in townhouse',\n",
        "        'Private room in home', 'Entire condo', 'Entire home', 'Houseboat', 'Private room in guest suite',\n",
        "        'Shared room in hostel', 'Entire loft']\n",
        "specific_dummies = pd.get_dummies(data['property_type'][data['property_type'].isin(for_)], prefix=\"proptype\")\n",
        "data = pd.concat([data, specific_dummies], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in for_:\n",
        "    data[\"proptype_\"+i].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "71SLluA8Jm-Y"
      },
      "id": "71SLluA8Jm-Y",
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating dummies for room type**"
      ],
      "metadata": {
        "id": "BDb1EtsBNfOm"
      },
      "id": "BDb1EtsBNfOm"
    },
    {
      "cell_type": "code",
      "source": [
        "specific_dummies = pd.get_dummies(data['room_type'], prefix=\"room_type\", drop_first=True)\n",
        "data = pd.concat([data, specific_dummies], axis=1)"
      ],
      "metadata": {
        "id": "g4vizOm0J1Pn"
      },
      "id": "g4vizOm0J1Pn",
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specific_dummies = pd.get_dummies(data['neighbourhood_cleansed'], prefix=\"neigh\", drop_first=True)\n",
        "data = pd.concat([data, specific_dummies], axis=1)"
      ],
      "metadata": {
        "id": "12TCg-jVKKMI"
      },
      "id": "12TCg-jVKKMI",
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bathrooms_text is in string, words. Should extract something.**"
      ],
      "metadata": {
        "id": "aqBOqlwrNnz2"
      },
      "id": "aqBOqlwrNnz2"
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"bathrooms_text\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wayrUEExLIdR",
        "outputId": "f245e76b-5df1-4e5a-863b-25fc79cf0adc"
      },
      "id": "wayrUEExLIdR",
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1.5 baths', '1.5 shared baths', '1 private bath', '1 shared bath',\n",
              "       '1 bath', '2.5 baths', '3.5 baths', '0 baths', 'Private half-bath',\n",
              "       '2 baths', '3 baths', '0 shared baths', 'Half-bath', nan,\n",
              "       '5 baths', 'Shared half-bath', '2 shared baths', '5.5 baths',\n",
              "       '4 baths', '4.5 baths', '4 shared baths', '17 baths',\n",
              "       '3 shared baths'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 469
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting times to UNIX type, for them to be meaningful**"
      ],
      "metadata": {
        "id": "0km_hkQbNw8W"
      },
      "id": "0km_hkQbNw8W"
    },
    {
      "cell_type": "code",
      "source": [
        "data['first_review'] = pd.to_datetime(data['first_review'])\n",
        "data['last_review'] = pd.to_datetime(data['last_review'])\n",
        "data['host_since'] = pd.to_datetime(data['host_since'])\n",
        "data['first_review_unix'] = (data['first_review'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "data['last_review_unix'] = (data['last_review'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "data['host_since_unix'] = (data['host_since'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
      ],
      "metadata": {
        "id": "zLfhldyeSF49"
      },
      "id": "zLfhldyeSF49",
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['last_review_unix'] = data['last_review_unix'].apply(lambda x: min(data['last_review_unix'][data['last_review_unix']>0]) if x <0 else x)"
      ],
      "metadata": {
        "id": "SlRWixeBSis1"
      },
      "id": "SlRWixeBSis1",
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['first_review_unix'] = data['first_review_unix'].apply(lambda x: min(data['first_review_unix'][data['first_review_unix']>0]) if x <0 else x)"
      ],
      "metadata": {
        "id": "RYlU3mOaOGHe"
      },
      "id": "RYlU3mOaOGHe",
      "execution_count": 472,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['host_since_unix'] = data['host_since_unix'].apply(lambda x: min(data['host_since_unix'][data['host_since_unix']>0]) if x <0 else x)"
      ],
      "metadata": {
        "id": "fbODmjW1sdTA"
      },
      "id": "fbODmjW1sdTA",
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill NaNs with the minimum of the series**"
      ],
      "metadata": {
        "id": "R8yYXwq5N4Ym"
      },
      "id": "R8yYXwq5N4Ym"
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"last_review_unix\"].fillna(min(data['last_review_unix']), inplace=True)\n",
        "data[\"first_review_unix\"].fillna(min(data['first_review_unix']), inplace=True)\n",
        "data[\"last_review_unix\"].fillna(min(data['last_review_unix']), inplace=True)"
      ],
      "metadata": {
        "id": "eILxtI9Lr0oZ"
      },
      "id": "eILxtI9Lr0oZ",
      "execution_count": 474,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Those features are numerical. FIlling their NaNs with zeros. One could fill in with the mean of them, but I deem there is some reason there are NaNs. So I fill in with zeros**"
      ],
      "metadata": {
        "id": "9L9RTvoVOAdm"
      },
      "id": "9L9RTvoVOAdm"
    },
    {
      "cell_type": "code",
      "source": [
        "to_zero = ['review_scores_communication', 'host_acceptance_rate', 'review_scores_communication', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_location', 'review_scores_value',\n",
        "           'review_scores_accuracy','review_scores_rating', 'reviews_per_month', 'bedrooms', 'beds', 'host_is_superhost', 'bathrooms_text']\n",
        "for i in to_zero:\n",
        "  data[i].fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "_dtSYLufUV3c"
      },
      "id": "_dtSYLufUV3c",
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"first_review\", \"last_review\"], inplace=True)"
      ],
      "metadata": {
        "id": "ruUdjHfHU4UV"
      },
      "id": "ruUdjHfHU4UV",
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No missing values now. Cool.**"
      ],
      "metadata": {
        "id": "jRjJ4JEWOX7O"
      },
      "id": "jRjJ4JEWOX7O"
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isna().sum().sort_values(ascending=False)\n",
        "missing_values = missing_values[missing_values>0]\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkS74-DxUzQO",
        "outputId": "278f083f-f1d1-48ad-899c-fedfcc4b6f26"
      },
      "id": "hkS74-DxUzQO",
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change half-bath to numeric value of 0.5**"
      ],
      "metadata": {
        "id": "XpkzwS-6Pwi2"
      },
      "id": "XpkzwS-6Pwi2"
    },
    {
      "cell_type": "code",
      "source": [
        "data['bathrooms_text'] = data['bathrooms_text'].apply(lambda x: str(x).replace(\"half-bath\", \"0.5\"))\n",
        "data['bathrooms_text'] = data['bathrooms_text'].apply(lambda x: str(x).replace(\"Half-bath\", \"0.5\"))"
      ],
      "metadata": {
        "id": "9vPFY8u4hvVP"
      },
      "id": "9vPFY8u4hvVP",
      "execution_count": 478,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get only numbers from the string. So just the number of baths.**"
      ],
      "metadata": {
        "id": "hLHIxbxjP2e9"
      },
      "id": "hLHIxbxjP2e9"
    },
    {
      "cell_type": "code",
      "source": [
        "data['bathrooms'] = data['bathrooms_text'].apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+',x)[0])"
      ],
      "metadata": {
        "id": "fFAh1Z61m1MN"
      },
      "id": "fFAh1Z61m1MN",
      "execution_count": 479,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['bathrooms']=data['bathrooms'].astype(\"float\")"
      ],
      "metadata": {
        "id": "HJ4kDovdm8W-"
      },
      "id": "HJ4kDovdm8W-",
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penalize the number of baths, if it is shared**"
      ],
      "metadata": {
        "id": "YbtI4DL-P-3m"
      },
      "id": "YbtI4DL-P-3m"
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in data.iterrows():\n",
        "    if \"share\" in row['bathrooms_text']:\n",
        "      data.at[index, 'bathrooms'] = 0.5*row['bathrooms']"
      ],
      "metadata": {
        "id": "ODqr8qoSmQJs"
      },
      "id": "ODqr8qoSmQJs",
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are dummies of them, so drop them**"
      ],
      "metadata": {
        "id": "uNuQ6oZkQGL1"
      },
      "id": "uNuQ6oZkQGL1"
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"host_since\", \"bathrooms_text\", \"property_type\", \"amenities\", \"room_type\"], inplace=True)"
      ],
      "metadata": {
        "id": "mFvEGHKfskKC"
      },
      "id": "mFvEGHKfskKC",
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aggregate availability. Weight all of them to numeraire **"
      ],
      "metadata": {
        "id": "iDuRPsX5QKCl"
      },
      "id": "iDuRPsX5QKCl"
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"aval\"] = (15.66/30)*data[\"availability_30\"] + (15.66/60)*data[\"availability_60\"] + (15.66/90)*data[\"availability_90\"] + (15.66/365)*data[\"availability_365\"]"
      ],
      "metadata": {
        "id": "DAFAK_uKuD0w"
      },
      "id": "DAFAK_uKuD0w",
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"availability_30\", \"availability_60\", \"availability_90\", \"availability_365\"], inplace=True)"
      ],
      "metadata": {
        "id": "MYDj6kIAucdo"
      },
      "id": "MYDj6kIAucdo",
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add data from TripAdvisor for the popular tourist amenities**"
      ],
      "metadata": {
        "id": "V8oC9tnxQWT9"
      },
      "id": "V8oC9tnxQWT9"
    },
    {
      "cell_type": "code",
      "source": [
        "# trip = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/PS2/data/december/trip.csv\")\n",
        "trip = pd.read_csv(\"data/december/trip.csv\")"
      ],
      "metadata": {
        "id": "yxcgGnaoHZC5"
      },
      "id": "yxcgGnaoHZC5",
      "execution_count": 485,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are number of reviews from TripAdvisor and Google. Normalize them via max-min**"
      ],
      "metadata": {
        "id": "c02Mnt0mQi9d"
      },
      "id": "c02Mnt0mQi9d"
    },
    {
      "cell_type": "code",
      "source": [
        "trip[\"g\"] = (trip[\"greviews\"] - min(trip[\"greviews\"]))/(max(trip[\"greviews\"] - min(trip[\"greviews\"])))"
      ],
      "metadata": {
        "id": "3iXZhCrxHk1W"
      },
      "id": "3iXZhCrxHk1W",
      "execution_count": 486,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trip[\"t\"] = (trip[\"treviews\"] - min(trip[\"treviews\"]))/(max(trip[\"treviews\"] - min(trip[\"treviews\"])))"
      ],
      "metadata": {
        "id": "Id1j8x5yIMKY"
      },
      "id": "Id1j8x5yIMKY",
      "execution_count": 487,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the mean score of TripAdvisor and Google**"
      ],
      "metadata": {
        "id": "XLloM-zIQpv8"
      },
      "id": "XLloM-zIQpv8"
    },
    {
      "cell_type": "code",
      "source": [
        "trip[\"score\"] = 100*((trip[\"g\"]+trip[\"t\"])/2)"
      ],
      "metadata": {
        "id": "sxhTFI-hI_YI"
      },
      "id": "sxhTFI-hI_YI",
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the formula $ament_{apartment} = \\sum_{amenity} \\frac{1}{distance_{apartment, amenity}}\\cdot ReviewScore_{amenity}$ to get the index. This index takes into account attractiveness of the place where apartment is, and distance to this from popular amenities** "
      ],
      "metadata": {
        "id": "CuClScHFQvIc"
      },
      "id": "CuClScHFQvIc"
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in data.iterrows():\n",
        "  ament = 0\n",
        "  for indeks, line in trip.iterrows():\n",
        "    ament += line['score']/(geopy.distance.distance(np.array(row[['latitude', 'longitude']]), line['location']).km)\n",
        "  data.at[index, \"ament\"] = ament"
      ],
      "metadata": {
        "id": "cZfD7sA9KhdG"
      },
      "id": "cZfD7sA9KhdG",
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNIX time is in seconds. Very large. So I divide to 10^6**"
      ],
      "metadata": {
        "id": "TogbywDJRs6M"
      },
      "id": "TogbywDJRs6M"
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"first_review_unix\"]=data[\"first_review_unix\"]/(10**6)\n",
        "data[\"last_review_unix\"]=data[\"last_review_unix\"]/(10**6)\n",
        "data[\"ament\"]=data[\"ament\"]/(10**6)\n"
      ],
      "metadata": {
        "id": "HSZ_L4IgRScD"
      },
      "id": "HSZ_L4IgRScD",
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop unnecessary features. And create lof of the target. Before dropping and did some analysis to check important variables, but I do not show this, omitting for clarity**"
      ],
      "metadata": {
        "id": "YZS7xHXPR26W"
      },
      "id": "YZS7xHXPR26W"
    },
    {
      "cell_type": "code",
      "source": [
        "drops = ['source', 'latitude', 'longitude', 'neighbourhood_cleansed','minimum_nights', 'maximum_nights',\n",
        " 'minimum_minimum_nights',\n",
        " 'maximum_minimum_nights',\n",
        " 'minimum_maximum_nights',\n",
        " 'maximum_maximum_nights',\n",
        " 'review_scores_accuracy',\n",
        " 'review_scores_cleanliness',\n",
        " 'review_scores_checkin',\n",
        " 'review_scores_communication',\n",
        " 'review_scores_location',\n",
        " 'review_scores_value', 'number_of_reviews_ltm', 'number_of_reviews_l30d',  'calculated_host_listings_count_entire_homes',\n",
        " 'calculated_host_listings_count_shared_rooms', 'Hot', 'water', 'dryer', 'alarm', 'proptype_Shared room in hostel', 'host_since_unix']\n",
        "df = data.drop(columns=drops)\n",
        "\n"
      ],
      "metadata": {
        "id": "K8GSIObuZe8i"
      },
      "id": "K8GSIObuZe8i",
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"logprice\"]=np.log(df[\"price\"])\n",
        "df = df.replace([-np.inf], 0)\n"
      ],
      "metadata": {
        "id": "SsJU7NDKdRuG"
      },
      "id": "SsJU7NDKdRuG",
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [ 'accommodates',\n",
        " 'bedrooms',\n",
        " 'beds',\n",
        " 'last_review_unix',\n",
        " 'bathrooms',\n",
        " 'aval',\n",
        " 'ament']\n",
        "for ind in lista:\n",
        "  df[ind+str(\"_2\")]=df[ind]*df[ind]"
      ],
      "metadata": {
        "id": "FEMANJ2ifRT3"
      },
      "id": "FEMANJ2ifRT3",
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create holdout sample**"
      ],
      "metadata": {
        "id": "j55thYnOSKiu"
      },
      "id": "j55thYnOSKiu"
    },
    {
      "cell_type": "code",
      "source": [
        "out_sample = df.sample(n=300)\n",
        "out_sample_X = out_sample.drop([\"logprice\", \"price\", \"id\", \"scrape_id\"],axis=1)\n",
        "out_sample_y =  out_sample[\"price\"]\n",
        "out_sample_y_log =  out_sample[\"logprice\"]\n",
        "df_learn = df.drop(out_sample.index)"
      ],
      "metadata": {
        "id": "-sjV73hHllUv"
      },
      "id": "-sjV73hHllUv",
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_learn_X = df_learn.drop([\"logprice\", \"price\", \"id\", \"scrape_id\"],axis=1)\n",
        "y = df_learn[\"price\"]\n",
        "log_y = df_learn[\"logprice\"]"
      ],
      "metadata": {
        "id": "93YO2xtwowxo"
      },
      "id": "93YO2xtwowxo",
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = df_learn_X.columns.to_list()\n",
        "neigh = filter(lambda x: x.startswith('neigh_'), columns)\n",
        "room_type = filter(lambda x: x.startswith('room_type_'), columns)\n",
        "proptype = filter(lambda x: x.startswith('proptype_'), columns)\n",
        "base = list(['host_acceptance_rate',\n",
        " 'host_is_superhost',\n",
        " 'host_listings_count',\n",
        " 'host_identity_verified',\n",
        " 'accommodates',\n",
        " 'bedrooms',\n",
        " 'beds',\n",
        " 'minimum_nights_avg_ntm',\n",
        " 'maximum_nights_avg_ntm',\n",
        " 'number_of_reviews',\n",
        " 'review_scores_rating',\n",
        " 'instant_bookable',\n",
        " 'calculated_host_listings_count',\n",
        " 'calculated_host_listings_count_private_rooms',\n",
        " 'reviews_per_month',\n",
        " 'Hangers',\n",
        " 'Dishes',\n",
        " 'linens',\n",
        " 'Wifi',\n",
        " 'Fire',\n",
        " 'Heating',\n",
        " 'Refrigerator',\n",
        " 'premises',\n",
        " 'Coffee',\n",
        " 'Smoke',\n",
        " 'Iron',\n",
        " 'parking',\n",
        " 'TV',\n",
        " 'Kitchen','first_review_unix',\n",
        " 'last_review_unix',\n",
        " 'bathrooms',\n",
        " 'aval',\n",
        " 'ament'])\n",
        "quad = list([ 'accommodates_2',\n",
        " 'bedrooms_2',\n",
        " 'beds_2',\n",
        " 'last_review_unix_2',\n",
        " 'bathrooms_2',\n",
        " 'aval_2',\n",
        " 'ament_2'])"
      ],
      "metadata": {
        "id": "i8xBp_5bpk4n"
      },
      "id": "i8xBp_5bpk4n",
      "execution_count": 546,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.regression.linear_model import OLS"
      ],
      "metadata": {
        "id": "3uKtjNOUw_nl"
      },
      "id": "3uKtjNOUw_nl",
      "execution_count": 547,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Four specifications**"
      ],
      "metadata": {
        "id": "5obACg6cSRxE"
      },
      "id": "5obACg6cSRxE"
    },
    {
      "cell_type": "code",
      "source": [
        "formula_1 = list(base)\n",
        "formula_2 = list(quad)\n",
        "formula_3 = list(neigh) + list(proptype) + list(room_type)\n",
        "formula_4 = formula_1 + formula_2 +formula_3"
      ],
      "metadata": {
        "id": "GTB8VzuPzDe3"
      },
      "id": "GTB8VzuPzDe3",
      "execution_count": 548,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {}\n",
        "\n",
        "#the OLS model\n",
        "\n",
        "def full_ols(dep, formula, name, datas):\n",
        "    model = OLS(datas[dep],datas[formula])\n",
        "    results = model.fit()\n",
        "    metrics[name] = {\"RMSE\":np.sqrt(results.mse_resid) , \"BIC\": results.bic}\n",
        "\n",
        "full_ols('price', formula_1, \"model_1\", df_learn)\n",
        "full_ols('price',formula_2, \"model_2\", df_learn)\n",
        "full_ols('price',formula_3, \"model_3\", df_learn)\n",
        "full_ols('price',formula_4, \"model_4\", df_learn)\n",
        "\n",
        "full_ols('logprice', formula_1, \"model_1_log\", df_learn)\n",
        "full_ols('logprice',formula_2, \"model_2_log\", df_learn)\n",
        "full_ols('logprice',formula_3, \"model_3_log\", df_learn)\n",
        "full_ols('logprice',formula_4, \"model_4_log\", df_learn)\n",
        "\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4dzatoWp3_u",
        "outputId": "ecae2336-d700-4334-b489-5291d3486fb6"
      },
      "id": "l4dzatoWp3_u",
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_1': {'RMSE': 962.1637043608615, 'BIC': 108159.24992701387}, 'model_2': {'RMSE': 963.153457435621, 'BIC': 107962.63425991997}, 'model_3': {'RMSE': 966.2213809951669, 'BIC': 108229.58560671254}, 'model_4': {'RMSE': 962.7532842609536, 'BIC': 108501.43496224325}, 'model_1_log': {'RMSE': 0.4479083734089472, 'BIC': 8280.58202927218}, 'model_2_log': {'RMSE': 0.7102543138695565, 'BIC': 14072.32786809198}, 'model_3_log': {'RMSE': 0.636512499918051, 'BIC': 12870.85836572309}, 'model_4_log': {'RMSE': 0.40647466223555845, 'BIC': 7351.173129348038}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "5aOz8BnuyBxr"
      },
      "id": "5aOz8BnuyBxr",
      "execution_count": 550,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = KFold(n_splits=4, random_state=2023, shuffle=True)"
      ],
      "metadata": {
        "id": "qcjj9IKDx_Jh"
      },
      "id": "qcjj9IKDx_Jh",
      "execution_count": 612,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    formula = X_train[formula_1]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_1])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_1_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "SViY3Onmw-1H"
      },
      "id": "SViY3Onmw-1H",
      "execution_count": 625,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    formula = X_train[formula_2]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_2])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_2_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "ZFx67YYNy1NV"
      },
      "id": "ZFx67YYNy1NV",
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    formula = X_train[formula_3]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_3])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_3_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "21f8Mo6Dy5QD"
      },
      "id": "21f8Mo6Dy5QD",
      "execution_count": 615,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    formula = X_train[formula_4]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_4])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_4_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "aUwY7WxPy9be"
      },
      "id": "aUwY7WxPy9be",
      "execution_count": 616,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
        "    formula = X_train[formula_1]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_1])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_1_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "tXzU1UHv2h_S"
      },
      "id": "tXzU1UHv2h_S",
      "execution_count": 617,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
        "    formula = X_train[formula_2]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_2])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_2_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "KcWuLqwn2pR6"
      },
      "id": "KcWuLqwn2pR6",
      "execution_count": 618,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
        "    formula = X_train[formula_3]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_3])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_3_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "ZsmF_y2a2qyi"
      },
      "id": "ZsmF_y2a2qyi",
      "execution_count": 619,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_results = []\n",
        "for train_index, test_index in k.split(df_learn_X):\n",
        "    # Get the training and test data for this fold\n",
        "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
        "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
        "    formula = X_train[formula_4]\n",
        "    y_train = list(y_train)\n",
        "    model = OLS(y_train,formula)\n",
        "    results = model.fit()\n",
        "    # Predict on the test data\n",
        "    y_pred = results.predict(X_test[formula_4])\n",
        "\n",
        "    # Calculate the RMSE for this fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_results.append(rmse)\n",
        "metrics[\"model_4_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
      ],
      "metadata": {
        "id": "Hc1Hg49-2r5L"
      },
      "id": "Hc1Hg49-2r5L",
      "execution_count": 620,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_ols('price', formula_1, \"model_out_1\", out_sample)\n",
        "full_ols('price', formula_1, \"model_out_2\", out_sample)\n",
        "full_ols('price', formula_1, \"model_out_3\", out_sample)\n",
        "full_ols('price', formula_4, \"model_out_4\", out_sample)\n",
        "full_ols('logprice', formula_1, \"model_out_1_log\", out_sample)\n",
        "full_ols('logprice', formula_1, \"model_out_2_log\", out_sample)\n",
        "full_ols('logprice', formula_1, \"model_out_3_log\", out_sample)\n",
        "full_ols('logprice', formula_4, \"model_out_4_log\", out_sample)"
      ],
      "metadata": {
        "id": "o5SddZd4zTJ9"
      },
      "id": "o5SddZd4zTJ9",
      "execution_count": 621,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.concat([pd.DataFrame(data=[\n",
        "[metrics[\"model_1\"][\"RMSE\"], metrics[\"model_2\"][\"RMSE\"], metrics[\"model_3\"][\"RMSE\"], metrics[\"model_4\"][\"RMSE\"]],\n",
        "[metrics[\"model_1\"][\"BIC\"], metrics[\"model_2\"][\"BIC\"], metrics[\"model_3\"][\"BIC\"], metrics[\"model_4\"][\"BIC\"]],\n",
        "\n",
        "[metrics[\"model_1_log\"][\"RMSE\"], metrics[\"model_2_log\"][\"RMSE\"], metrics[\"model_3_log\"][\"RMSE\"], metrics[\"model_4_log\"][\"RMSE\"]],\n",
        "[metrics[\"model_1_log\"][\"BIC\"], metrics[\"model_2_log\"][\"BIC\"], metrics[\"model_3_log\"][\"BIC\"], metrics[\"model_4_log\"][\"BIC\"]],\n",
        "\n",
        "[metrics[\"model_1_k\"][\"RMSE_1\"], metrics[\"model_2_k\"][\"RMSE_1\"], metrics[\"model_3_k\"][\"RMSE_1\"], metrics[\"model_4_k\"][\"RMSE_1\"]],\n",
        "[metrics[\"model_1_k\"][\"RMSE_2\"], metrics[\"model_2_k\"][\"RMSE_2\"],metrics[\"model_3_k\"][\"RMSE_2\"],metrics[\"model_4_k\"][\"RMSE_2\"]],\n",
        "[metrics[\"model_1_k\"][\"RMSE_3\"], metrics[\"model_2_k\"][\"RMSE_3\"],metrics[\"model_3_k\"][\"RMSE_3\"],metrics[\"model_4_k\"][\"RMSE_3\"]],\n",
        "[metrics[\"model_1_k\"][\"RMSE_4\"], metrics[\"model_2_k\"][\"RMSE_4\"],metrics[\"model_3_k\"][\"RMSE_4\"],metrics[\"model_4_k\"][\"RMSE_4\"]],\n",
        "[metrics[\"model_1_k\"][\"RMSE_average\"], metrics[\"model_2_k\"][\"RMSE_average\"],metrics[\"model_3_k\"][\"RMSE_average\"],metrics[\"model_4_k\"][\"RMSE_average\"]],\n",
        "\n",
        "[metrics[\"model_1_k_log\"][\"RMSE_1\"], metrics[\"model_2_k_log\"][\"RMSE_1\"], metrics[\"model_3_k_log\"][\"RMSE_1\"], metrics[\"model_4_k_log\"][\"RMSE_1\"]],\n",
        "[metrics[\"model_1_k_log\"][\"RMSE_2\"], metrics[\"model_2_k_log\"][\"RMSE_2\"],metrics[\"model_3_k_log\"][\"RMSE_2\"],metrics[\"model_4_k_log\"][\"RMSE_2\"]],\n",
        "[metrics[\"model_1_k_log\"][\"RMSE_3\"], metrics[\"model_2_k_log\"][\"RMSE_3\"],metrics[\"model_3_k_log\"][\"RMSE_3\"],metrics[\"model_4_k_log\"][\"RMSE_3\"]],\n",
        "[metrics[\"model_1_k_log\"][\"RMSE_4\"], metrics[\"model_2_k_log\"][\"RMSE_4\"],metrics[\"model_3_k_log\"][\"RMSE_4\"],metrics[\"model_4_k_log\"][\"RMSE_4\"]],\n",
        "[metrics[\"model_1_k_log\"][\"RMSE_average\"], metrics[\"model_2_k_log\"][\"RMSE_average\"],metrics[\"model_3_k_log\"][\"RMSE_average\"],metrics[\"model_4_k_log\"][\"RMSE_average\"]],\n",
        "\n",
        "\n",
        "[metrics[\"model_out_1\"][\"RMSE\"], metrics[\"model_out_2\"][\"RMSE\"],metrics[\"model_out_3\"][\"RMSE\"],metrics[\"model_out_4\"][\"RMSE\"]],\n",
        "[metrics[\"model_out_1\"][\"BIC\"], metrics[\"model_out_2\"][\"BIC\"],metrics[\"model_out_3\"][\"BIC\"],metrics[\"model_out_4\"][\"BIC\"]],\n",
        "\n",
        "[metrics[\"model_out_1_log\"][\"RMSE\"], metrics[\"model_out_2_log\"][\"RMSE\"],metrics[\"model_out_3_log\"][\"RMSE\"],metrics[\"model_out_4_log\"][\"RMSE\"]],\n",
        "[metrics[\"model_out_1_log\"][\"BIC\"], metrics[\"model_out_2_log\"][\"BIC\"],metrics[\"model_out_3_log\"][\"BIC\"],metrics[\"model_out_4_log\"][\"BIC\"]]\n",
        "\n",
        " ], columns=[\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"]).rename({0: \"RMSE - full sample\", 1: \"BIC - full sample\", \n",
        "                                                                  2: \"RMSE - full sample log\", 3: \"BIC - full sample log\", \n",
        "                                                                  4:\"Fold 1\", 5:\"Fold 2\", 6:\"Fold 3\", 7:\"Fold 4\", 8:\"Average RMSE\", \n",
        "                                                                  \n",
        "                                                                  9:\"Fold 1 log\", 10:\"Fold 2 log\", 11:\"Fold 3 log\", 12:\"Fold 4 log\", 13:\"Average RMSE log\", \n",
        "                                                                  14:\"Out sample RMSE\", 15:\"Out sample BIC\",\n",
        "                                                                   16:\"Out sample RMSE log\", 17:\"Out sample BIC log\"\n",
        "                                                                   }, axis=0),\n",
        "    ]).round(3)\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KImtL_HqzIP2",
        "outputId": "b9d87cb3-204a-4f85-db7f-de012d9fe25d"
      },
      "id": "KImtL_HqzIP2",
      "execution_count": 651,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model 1     Model 2     Model 3      Model 4\n",
            "RMSE - full sample          962.164     963.153     966.221      962.753\n",
            "BIC - full sample        108159.250  107962.634  108229.586   108501.435\n",
            "RMSE - full sample log        0.448       0.710       0.637        0.406\n",
            "BIC - full sample log      8280.582   14072.328   12870.858     7351.173\n",
            "Fold 1                      264.066     259.283     271.969      273.063\n",
            "Fold 2                  1126194.321     156.485     163.930  1142422.561\n",
            "Fold 3                     1774.156    1775.863    1775.575     1783.805\n",
            "Fold 4                      702.791     695.494     697.673      705.836\n",
            "Average RMSE             282233.833     721.781     727.287   286296.316\n",
            "Fold 1 log                    0.481       0.734       0.658        0.441\n",
            "Fold 2 log                 1325.175       1.012       0.685     1137.202\n",
            "Fold 3 log                    0.449       0.874       0.605        0.638\n",
            "Fold 4 log                    0.443       0.698       0.610        0.413\n",
            "Average RMSE log            331.637       0.829       0.639      284.674\n",
            "Out sample RMSE             134.202     134.202     134.202       91.662\n",
            "Out sample BIC             3948.813    3948.813    3948.813     3903.704\n",
            "Out sample RMSE log           0.413       0.413       0.413        0.344\n",
            "Out sample BIC log          478.802     478.802     478.802      552.017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By RMSE on full sample Model 1 is the best, but considering BIC Model 2 is the best one. On log scale Model 4 is the best one, with BIC also. CV shows that Model 2 and Model 3 are the best ones, in the log scale target also.Holdout results differ.**"
      ],
      "metadata": {
        "id": "YJD1FjseSXuf"
      },
      "id": "YJD1FjseSXuf"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Lasso \n",
        "from sklearn import metrics "
      ],
      "metadata": {
        "id": "rjDNgBGa5AuE"
      },
      "id": "rjDNgBGa5AuE",
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_1], y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZsCJYSt0fLb",
        "outputId": "b01a4ac4-f429-41ef-9fd1-c52517ac48d2"
      },
      "id": "qZsCJYSt0fLb",
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29    3000\n",
              "2     0.01\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_2], y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQlfMwLIHBzM",
        "outputId": "9206e154-a7d6-4a34-d990-f37cfe09a201"
      },
      "id": "sQlfMwLIHBzM",
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0001\n",
              "1     0.001\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_3], y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxjpGZSvHEMk",
        "outputId": "8a159cbb-e607-4b36-c5b2-83eb5b3718bd"
      },
      "id": "vxjpGZSvHEMk",
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13    1.0\n",
              "11    0.8\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 422
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_4], y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJh5rUhmHJHa",
        "outputId": "7ea3f4b7-d5cc-41a3-9d58-40db4416988e"
      },
      "id": "cJh5rUhmHJHa",
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29    3000\n",
              "28    2000\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_1], log_y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPlZH2ZHMm7",
        "outputId": "d11342d8-f533-4ff2-bb0b-3580d514074b"
      },
      "id": "UhPlZH2ZHMm7",
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29    3000\n",
              "28    2000\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_2], log_y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E26BeulDHRMk",
        "outputId": "a9c155bf-3798-41d1-9aa9-fc2b711c053e"
      },
      "id": "E26BeulDHRMk",
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0001\n",
              "1     0.001\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_3], log_y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hvrp6A6HUJV",
        "outputId": "47752422-01cf-4a2f-c9a8-c931757925aa"
      },
      "id": "8hvrp6A6HUJV",
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.001\n",
              "0    0.0001\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
        " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
        " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
        "folds = 4\n",
        "# cross validation\n",
        "model_cv = GridSearchCV(estimator = lasso, \n",
        "                        param_grid = params, \n",
        "                        scoring= 'neg_mean_absolute_error', \n",
        "                        cv = 4)            \n",
        "\n",
        "model_cv.fit(df_learn_X[formula_4], log_y) \n",
        "\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "\n",
        "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7B29aKZHXfj",
        "outputId": "82f387b3-217a-4579-f26a-6c0503e21731"
      },
      "id": "u7B29aKZHXfj",
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29    3000\n",
              "28    2000\n",
              "Name: param_alpha, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formulas = [formula_1, formula_2, formula_3, formula_4]\n",
        "y_alpha = [0.01, 0.001, 0.8, 2000]\n",
        "ylog_alpha = [2000, 0.001,0.001,2000]\n",
        "n=0\n",
        "for i in y_alpha:\n",
        "  lasso = Lasso(alpha=i)\n",
        "  lasso.fit(df_learn_X[formulas[n]],  y)\n",
        "  y_pred = lasso.predict(out_sample_X[formulas[n]])\n",
        "  n += 1\n",
        "  print(np.sqrt(metrics.mean_squared_error(out_sample_y,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niYgAU3AFrFU",
        "outputId": "de6d747f-d31a-42f3-d9bd-94ca98c8b5d6"
      },
      "id": "niYgAU3AFrFU",
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148.0293757579665\n",
            "150.4923232905115\n",
            "154.14600700112607\n",
            "160.70124533576086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=0\n",
        "for i in ylog_alpha:\n",
        "  lasso = Lasso(alpha=i)\n",
        "  lasso.fit(df_learn_X[formulas[n]],  log_y)\n",
        "  y_pred = lasso.predict(out_sample_X[formulas[n]])\n",
        "  n += 1\n",
        "  print(np.sqrt(metrics.mean_squared_error(out_sample_y_log,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWBDZGJgI7O6",
        "outputId": "b7cf0e4a-046b-4ef5-f964-e0a911579d84"
      },
      "id": "KWBDZGJgI7O6",
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5576329220871954\n",
            "0.5519331212161148\n",
            "0.4629085168955835\n",
            "0.5567455219323949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n"
      ],
      "metadata": {
        "id": "wQwSZlArLMeD"
      },
      "id": "wQwSZlArLMeD",
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_1],y)\n",
        "\n",
        "# print(xgb_grid.best_score_)\n",
        "# print(xgb_grid.best_params_)\n",
        "\n",
        "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MUjSMK9J4M0",
        "outputId": "34e5c41d-9146-4c91-eafe-4c83cbdb9a54"
      },
      "id": "0MUjSMK9J4M0",
      "execution_count": 639,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127.51394744427928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_2],y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_2]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WQyzC4uO0V5",
        "outputId": "aa88f183-a0e2-4c3a-b85a-fcf81ff40ac1"
      },
      "id": "8WQyzC4uO0V5",
      "execution_count": 640,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139.65707500696715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_3],y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_3]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO-T3RVAO2j6",
        "outputId": "6aab2319-8dbd-4a1b-86ea-ab673c37eda5"
      },
      "id": "DO-T3RVAO2j6",
      "execution_count": 641,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180.64360955690316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_4],y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_4]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG7EOVutO5Sp",
        "outputId": "c3d631c9-2098-4e19-e2d5-88cbbb7d75f4"
      },
      "id": "nG7EOVutO5Sp",
      "execution_count": 642,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118.02371153809318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_1],log_y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_grid.predict(out_sample_X[formula_1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfOwrb7bO65x",
        "outputId": "f43329da-cc1d-40f5-fe6d-e3799522cdd9"
      },
      "id": "tfOwrb7bO65x",
      "execution_count": 643,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.32226302998271317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_2],log_y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_grid.predict(out_sample_X[formula_2]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv_nVA6iO9-5",
        "outputId": "c32cdcc5-dd5a-4940-9e04-6708830254e7"
      },
      "id": "jv_nVA6iO9-5",
      "execution_count": 644,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3730223366657394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_3],log_y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_grid.predict(out_sample_X[formula_3]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3N74ZOoPApw",
        "outputId": "b886e320-30d0-4cb3-a085-c2eca8dfe477"
      },
      "id": "I3N74ZOoPApw",
      "execution_count": 645,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44644560390678417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb1 = XGBRegressor(seed = 2023)\n",
        "parameters = {'nthread':[-1],\n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.03, .07],\n",
        "              'max_depth': [5, 10],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.85],\n",
        "              'colsample_bytree': [0.5],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        parameters,\n",
        "                        cv = 4,\n",
        "                        n_jobs = -1,\n",
        "                        scoring=\"neg_root_mean_squared_error\")\n",
        "\n",
        "xgb_grid.fit(df_learn_X[formula_4],log_y)\n",
        "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_grid.predict(out_sample_X[formula_4]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOT1iHzVPDSI",
        "outputId": "e6c2a733-ab28-4e8b-c268-84fa688528dd"
      },
      "id": "oOT1iHzVPDSI",
      "execution_count": 646,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3172774335626686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.concat([pd.DataFrame(data=[\n",
        "[metrics[\"model_out_1\"][\"RMSE\"], metrics[\"model_out_2\"][\"RMSE\"],metrics[\"model_out_3\"][\"RMSE\"],metrics[\"model_out_4\"][\"RMSE\"]],\n",
        "\n",
        "[metrics[\"model_out_1_log\"][\"RMSE\"], metrics[\"model_out_2_log\"][\"RMSE\"],metrics[\"model_out_3_log\"][\"RMSE\"],metrics[\"model_out_4_log\"][\"RMSE\"]],\n",
        "[\"148\", \"150.5\", \"154.2\", \"160.7\" ],\n",
        "[\"0.558\", \"0.551\", \"046\", \"0.557\" ],\n",
        "[\"127.51\", \"139.65\", \"180.64\", \"118\" ],\n",
        "[\"0.322\", \"0.373\", \"0.44\", \"0.317\" ]\n",
        "\n",
        " ], columns=[\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"]).rename({ 0:\"RMSE: Out sample OLS price\", \n",
        "                                                                   1:\"RMSE: Out sample OLS log price\", \n",
        "                                                                   2: \"RMSE: Out Sample: Lasso Price\",\n",
        "                                                                   3: \"RMSE: Out Sample: Lasso Log Price\", \n",
        "                                                                   4: \"RMSE: Out Sample: XGB Price\", \n",
        "                                                                   5: \"RMSE: Out Sample: XGB Log Price\", \n",
        "                                                                   }, axis=0),\n",
        "    ]).round(3)\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzSQ-W_zhuWZ",
        "outputId": "e839cb06-79c1-41c8-9c60-d6e1486820e5"
      },
      "id": "wzSQ-W_zhuWZ",
      "execution_count": 652,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Model 1     Model 2     Model 3  \\\n",
            "RMSE: Out sample OLS price         134.201855  134.201855  134.201855   \n",
            "RMSE: Out sample OLS log price       0.413124    0.413124    0.413124   \n",
            "RMSE: Out Sample: Lasso Price             148       150.5       154.2   \n",
            "RMSE: Out Sample: Lasso Log Price       0.558       0.551         046   \n",
            "RMSE: Out Sample: XGB Price            127.51      139.65      180.64   \n",
            "RMSE: Out Sample: XGB Log Price         0.322       0.373        0.44   \n",
            "\n",
            "                                     Model 4  \n",
            "RMSE: Out sample OLS price         91.661515  \n",
            "RMSE: Out sample OLS log price      0.343681  \n",
            "RMSE: Out Sample: Lasso Price          160.7  \n",
            "RMSE: Out Sample: Lasso Log Price      0.557  \n",
            "RMSE: Out Sample: XGB Price              118  \n",
            "RMSE: Out Sample: XGB Log Price        0.317  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In OLS Model 4 wins. In Lasso Model 1 for price, and Model 4 for log price. For XGB also Model 4 wins. Seemingly, althoug there is evidence of overfitting in OLS Model 4, because of many features it did best in hold out data as other types of models**"
      ],
      "metadata": {
        "id": "vA9lpLRIjGAf"
      },
      "id": "vA9lpLRIjGAf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}