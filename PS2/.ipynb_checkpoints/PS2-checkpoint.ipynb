{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "458eb6de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "458eb6de",
    "outputId": "4165c534-4130-402b-ff79-780cd2fb86c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopy.distance\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.options.display.max_rows = 10000\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zwdoNekcLyrf",
   "metadata": {
    "id": "zwdoNekcLyrf"
   },
   "source": [
    "**Loading the dataset for December**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "ba906658",
   "metadata": {
    "id": "ba906658"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/PS2/data/december/listings.csv\")\n",
    "data = pd.read_csv(\"data/december/listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G3uR6ziRL7r2",
   "metadata": {
    "id": "G3uR6ziRL7r2"
   },
   "source": [
    "**Droping unnecessary columns. Some of them has a lot NaNs. Some of them are just meaningless for prediction. Or is similar to other feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "81e9d60c",
   "metadata": {
    "id": "81e9d60c"
   },
   "outputs": [],
   "source": [
    "drops = [\"calendar_updated\", \"neighbourhood\", \"host_response_time\", \"host_response_rate\",\n",
    "         \"host_neighbourhood\", \"has_availability\",\"host_verifications\", \"host_has_profile_pic\", \"host_total_listings_count\",\n",
    "    \"license\",\n",
    "    \"neighbourhood_group_cleansed\",\n",
    "    \"bathrooms\",\n",
    "    \"host_thumbnail_url\",\n",
    "    \"host_picture_url\",\n",
    "    \"listing_url\",\n",
    "    \"picture_url\",\n",
    "    \"host_url\",\n",
    "    \"last_scraped\",\n",
    "    \"description\", \"calendar_last_scraped\",\n",
    "    \"neighborhood_overview\",\n",
    "    \"host_about\",\n",
    "    \"name\", \"host_location\", \"host_id\", \"host_name\"]\n",
    "data.drop(columns=drops, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CU-cObx1MYO6",
   "metadata": {
    "id": "CU-cObx1MYO6"
   },
   "source": [
    "**Converting percentage values to float**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "6345d669",
   "metadata": {
    "id": "6345d669"
   },
   "outputs": [],
   "source": [
    "data['host_acceptance_rate'] = data['host_acceptance_rate'].str.rstrip(\"%\").astype(float)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2Xajqz0MkrZ",
   "metadata": {
    "id": "s2Xajqz0MkrZ"
   },
   "source": [
    "**Cleaning the target (price)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "d1a76454",
   "metadata": {
    "id": "d1a76454"
   },
   "outputs": [],
   "source": [
    "data['price'] = data['price'].str.replace(r'[$,]', '').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A4CQGtyMMp7X",
   "metadata": {
    "id": "A4CQGtyMMp7X"
   },
   "source": [
    "**Checking for the outliers. Just 2. Seems OK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "ce339bb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce339bb8",
    "outputId": "97b1b293-a71e-411a-e97c-700d343adad4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798     26696.0\n",
       "1144    71536.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prices == 0\n",
    "# prices >25k\n",
    "data[data[\"price\"]>25000][\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51WJrK0hMwn_",
   "metadata": {
    "id": "51WJrK0hMwn_"
   },
   "source": [
    "**Converting to binary variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "a4200cb6",
   "metadata": {
    "id": "a4200cb6"
   },
   "outputs": [],
   "source": [
    "data['host_is_superhost'] = data['host_is_superhost'].apply(lambda x: 1 if x == 't' else (0 if x == 'f' else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "ABMhL1pzjMcd",
   "metadata": {
    "id": "ABMhL1pzjMcd"
   },
   "outputs": [],
   "source": [
    "data['host_identity_verified'] = data['host_identity_verified'].apply(lambda x: 1 if x == 't' else (0 if x == 'f' else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d6ca4d49",
   "metadata": {
    "id": "d6ca4d49"
   },
   "outputs": [],
   "source": [
    "data[\"host_identity_verified\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "33cd6e90",
   "metadata": {
    "id": "33cd6e90"
   },
   "outputs": [],
   "source": [
    "data['instant_bookable'] = data['instant_bookable'].apply(lambda x: 1 if x == 't' else (0 if x == 'f' else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z-_avc1dM3sN",
   "metadata": {
    "id": "Z-_avc1dM3sN"
   },
   "source": [
    "**Cleaning the string in amenities feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "c07e11da",
   "metadata": {
    "id": "c07e11da"
   },
   "outputs": [],
   "source": [
    "data['amenities'] = data['amenities'].apply(lambda x: re.sub(r'\\\\u\\w{4}', '', re.sub(r'\\\\', '', re.sub(r'\\[', '',  re.sub(r'\\]', '', re.sub(r'\"', '', re.sub(r',', '', x)))))  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jUN_Pz1JM9-U",
   "metadata": {
    "id": "jUN_Pz1JM9-U"
   },
   "source": [
    "**Collecting all words in a list for each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0b84c106",
   "metadata": {
    "id": "0b84c106"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "data['amenities'].apply(lambda x:  words.append(x.split(\" \")))\n",
    "flat_list = []\n",
    "for sub_list in words:\n",
    "    for item in sub_list:\n",
    "        flat_list.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lBaYIRLPNHDY",
   "metadata": {
    "id": "lBaYIRLPNHDY"
   },
   "source": [
    "**Droping meaningless and less frequent words. Then choosing the most frequent ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "3916e9ad",
   "metadata": {
    "id": "3916e9ad"
   },
   "outputs": [],
   "source": [
    "ab = pd.DataFrame(pd.Series(flat_list).value_counts())\n",
    "ab.columns = [\"counts\"]\n",
    "ab = ab[ab[\"counts\"]>600]\n",
    "ba = ab.transpose()\n",
    "ba = ba.drop(columns=[\"and\", \"allowed\", \"Private\", \"Essentials\",\"silverware\",\\\n",
    "                      \"Long\", \"Hair\", \"stays\", \"term\", \"Bed\", \"Shampoo\", \"Cooking\", \"basics\", \"u2013\",\\\n",
    "                      \"Paid\", \"Carbon\", \"monoxide\", \"maker\"\n",
    "                     ], axis=1)\n",
    "findd = ba.columns[:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xnASUH7ENViJ",
   "metadata": {
    "id": "xnASUH7ENViJ"
   },
   "source": [
    "**Creating dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "0000a76b",
   "metadata": {
    "id": "0000a76b"
   },
   "outputs": [],
   "source": [
    "for ind, row in data.iterrows():\n",
    "    for i in list(set(row[\"amenities\"].split(\" \")) & set(findd)):\n",
    "        data.at[ind, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "c1804d34",
   "metadata": {
    "id": "c1804d34"
   },
   "outputs": [],
   "source": [
    "for i in findd:\n",
    "    data[i].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G1cZeipzNaGe",
   "metadata": {
    "id": "G1cZeipzNaGe"
   },
   "source": [
    "**Creating dummies for property type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "4143018c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4143018c",
    "outputId": "b5048f7b-c051-4731-eb35-afb4caef8f31",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entire rental unit                   2384\n",
       "Entire condo                         1284\n",
       "Private room in rental unit           520\n",
       "Entire home                           432\n",
       "Private room in bed and breakfast     294\n",
       "Entire townhouse                      213\n",
       "Entire loft                           186\n",
       "Private room in condo                 135\n",
       "Houseboat                             132\n",
       "Private room in home                  130\n",
       "Room in boutique hotel                122\n",
       "Room in hotel                         117\n",
       "Private room in houseboat             102\n",
       "Private room in guest suite            99\n",
       "Private room in townhouse              91\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"property_type\"].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "3ad1cea0",
   "metadata": {
    "id": "3ad1cea0"
   },
   "outputs": [],
   "source": [
    "for_ = ['Private room in houseboat', 'Boat', 'Entire rental unit',\n",
    "        'Private room in bed and breakfast', 'Entire villa','Private room in townhouse',\n",
    "        'Private room in home', 'Entire condo', 'Entire home', 'Houseboat', 'Private room in guest suite',\n",
    "        'Shared room in hostel', 'Entire loft']\n",
    "specific_dummies = pd.get_dummies(data['property_type'][data['property_type'].isin(for_)], prefix=\"proptype\")\n",
    "data = pd.concat([data, specific_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "71SLluA8Jm-Y",
   "metadata": {
    "id": "71SLluA8Jm-Y"
   },
   "outputs": [],
   "source": [
    "for i in for_:\n",
    "    data[\"proptype_\"+i].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BDb1EtsBNfOm",
   "metadata": {
    "id": "BDb1EtsBNfOm"
   },
   "source": [
    "**Creating dummies for room type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "g4vizOm0J1Pn",
   "metadata": {
    "id": "g4vizOm0J1Pn"
   },
   "outputs": [],
   "source": [
    "specific_dummies = pd.get_dummies(data['room_type'], prefix=\"room_type\", drop_first=True)\n",
    "data = pd.concat([data, specific_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "12TCg-jVKKMI",
   "metadata": {
    "id": "12TCg-jVKKMI"
   },
   "outputs": [],
   "source": [
    "specific_dummies = pd.get_dummies(data['neighbourhood_cleansed'], prefix=\"neigh\", drop_first=True)\n",
    "data = pd.concat([data, specific_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqBOqlwrNnz2",
   "metadata": {
    "id": "aqBOqlwrNnz2"
   },
   "source": [
    "**bathrooms_text is in string, words. Should extract something.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "wayrUEExLIdR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wayrUEExLIdR",
    "outputId": "f245e76b-5df1-4e5a-863b-25fc79cf0adc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.5 baths', '1.5 shared baths', '1 private bath', '1 shared bath',\n",
       "       '1 bath', '2.5 baths', '3.5 baths', '0 baths', 'Private half-bath',\n",
       "       '2 baths', '3 baths', '0 shared baths', 'Half-bath', nan,\n",
       "       '5 baths', 'Shared half-bath', '2 shared baths', '5.5 baths',\n",
       "       '4 baths', '4.5 baths', '4 shared baths', '17 baths',\n",
       "       '3 shared baths'], dtype=object)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"bathrooms_text\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0km_hkQbNw8W",
   "metadata": {
    "id": "0km_hkQbNw8W"
   },
   "source": [
    "**Converting times to UNIX type, for them to be meaningful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "zLfhldyeSF49",
   "metadata": {
    "id": "zLfhldyeSF49"
   },
   "outputs": [],
   "source": [
    "data['first_review'] = pd.to_datetime(data['first_review'])\n",
    "data['last_review'] = pd.to_datetime(data['last_review'])\n",
    "data['host_since'] = pd.to_datetime(data['host_since'])\n",
    "data['first_review_unix'] = (data['first_review'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "data['last_review_unix'] = (data['last_review'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "data['host_since_unix'] = (data['host_since'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "SlRWixeBSis1",
   "metadata": {
    "id": "SlRWixeBSis1"
   },
   "outputs": [],
   "source": [
    "data['last_review_unix'] = data['last_review_unix'].apply(lambda x: min(data['last_review_unix'][data['last_review_unix']>0]) if x <0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "RYlU3mOaOGHe",
   "metadata": {
    "id": "RYlU3mOaOGHe"
   },
   "outputs": [],
   "source": [
    "data['first_review_unix'] = data['first_review_unix'].apply(lambda x: min(data['first_review_unix'][data['first_review_unix']>0]) if x <0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "fbODmjW1sdTA",
   "metadata": {
    "id": "fbODmjW1sdTA"
   },
   "outputs": [],
   "source": [
    "data['host_since_unix'] = data['host_since_unix'].apply(lambda x: min(data['host_since_unix'][data['host_since_unix']>0]) if x <0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R8yYXwq5N4Ym",
   "metadata": {
    "id": "R8yYXwq5N4Ym"
   },
   "source": [
    "**Fill NaNs with the minimum of the series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "eILxtI9Lr0oZ",
   "metadata": {
    "id": "eILxtI9Lr0oZ"
   },
   "outputs": [],
   "source": [
    "data[\"last_review_unix\"].fillna(min(data['last_review_unix']), inplace=True)\n",
    "data[\"first_review_unix\"].fillna(min(data['first_review_unix']), inplace=True)\n",
    "data[\"last_review_unix\"].fillna(min(data['last_review_unix']), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9L9RTvoVOAdm",
   "metadata": {
    "id": "9L9RTvoVOAdm"
   },
   "source": [
    "**Those features are numerical. FIlling their NaNs with zeros. One could fill in with the mean of them, but I deem there is some reason there are NaNs. So I fill in with zeros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "_dtSYLufUV3c",
   "metadata": {
    "id": "_dtSYLufUV3c"
   },
   "outputs": [],
   "source": [
    "to_zero = ['review_scores_communication', 'host_acceptance_rate', 'review_scores_communication', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_location', 'review_scores_value',\n",
    "           'review_scores_accuracy','review_scores_rating', 'reviews_per_month', 'bedrooms', 'beds', 'host_is_superhost', 'bathrooms_text']\n",
    "for i in to_zero:\n",
    "  data[i].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ruUdjHfHU4UV",
   "metadata": {
    "id": "ruUdjHfHU4UV"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"first_review\", \"last_review\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jRjJ4JEWOX7O",
   "metadata": {
    "id": "jRjJ4JEWOX7O"
   },
   "source": [
    "**No missing values now. Cool.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "hkS74-DxUzQO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkS74-DxUzQO",
    "outputId": "278f083f-f1d1-48ad-899c-fedfcc4b6f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isna().sum().sort_values(ascending=False)\n",
    "missing_values = missing_values[missing_values>0]\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XpkzwS-6Pwi2",
   "metadata": {
    "id": "XpkzwS-6Pwi2"
   },
   "source": [
    "**Change half-bath to numeric value of 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "9vPFY8u4hvVP",
   "metadata": {
    "id": "9vPFY8u4hvVP"
   },
   "outputs": [],
   "source": [
    "data['bathrooms_text'] = data['bathrooms_text'].apply(lambda x: str(x).replace(\"half-bath\", \"0.5\"))\n",
    "data['bathrooms_text'] = data['bathrooms_text'].apply(lambda x: str(x).replace(\"Half-bath\", \"0.5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hLHIxbxjP2e9",
   "metadata": {
    "id": "hLHIxbxjP2e9"
   },
   "source": [
    "**Get only numbers from the string. So just the number of baths.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "fFAh1Z61m1MN",
   "metadata": {
    "id": "fFAh1Z61m1MN"
   },
   "outputs": [],
   "source": [
    "data['bathrooms'] = data['bathrooms_text'].apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+',x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "HJ4kDovdm8W-",
   "metadata": {
    "id": "HJ4kDovdm8W-"
   },
   "outputs": [],
   "source": [
    "data['bathrooms']=data['bathrooms'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YbtI4DL-P-3m",
   "metadata": {
    "id": "YbtI4DL-P-3m"
   },
   "source": [
    "**Penalize the number of baths, if it is shared**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "ODqr8qoSmQJs",
   "metadata": {
    "id": "ODqr8qoSmQJs"
   },
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if \"share\" in row['bathrooms_text']:\n",
    "      data.at[index, 'bathrooms'] = 0.5*row['bathrooms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uNuQ6oZkQGL1",
   "metadata": {
    "id": "uNuQ6oZkQGL1"
   },
   "source": [
    "**There are dummies of them, so drop them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "mFvEGHKfskKC",
   "metadata": {
    "id": "mFvEGHKfskKC"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"host_since\", \"bathrooms_text\", \"property_type\", \"amenities\", \"room_type\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iDuRPsX5QKCl",
   "metadata": {
    "id": "iDuRPsX5QKCl"
   },
   "source": [
    "**Aggregate availability. Weight all of them to numeraire **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "DAFAK_uKuD0w",
   "metadata": {
    "id": "DAFAK_uKuD0w"
   },
   "outputs": [],
   "source": [
    "data[\"aval\"] = (15.66/30)*data[\"availability_30\"] + (15.66/60)*data[\"availability_60\"] + (15.66/90)*data[\"availability_90\"] + (15.66/365)*data[\"availability_365\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "MYDj6kIAucdo",
   "metadata": {
    "id": "MYDj6kIAucdo"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"availability_30\", \"availability_60\", \"availability_90\", \"availability_365\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V8oC9tnxQWT9",
   "metadata": {
    "id": "V8oC9tnxQWT9"
   },
   "source": [
    "**Add data from TripAdvisor for the popular tourist amenities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "yxcgGnaoHZC5",
   "metadata": {
    "id": "yxcgGnaoHZC5"
   },
   "outputs": [],
   "source": [
    "# trip = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/PS2/data/december/trip.csv\")\n",
    "trip = pd.read_csv(\"data/december/trip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02Mnt0mQi9d",
   "metadata": {
    "id": "c02Mnt0mQi9d"
   },
   "source": [
    "**There are number of reviews from TripAdvisor and Google. Normalize them via max-min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "3iXZhCrxHk1W",
   "metadata": {
    "id": "3iXZhCrxHk1W"
   },
   "outputs": [],
   "source": [
    "trip[\"g\"] = (trip[\"greviews\"] - min(trip[\"greviews\"]))/(max(trip[\"greviews\"] - min(trip[\"greviews\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "Id1j8x5yIMKY",
   "metadata": {
    "id": "Id1j8x5yIMKY"
   },
   "outputs": [],
   "source": [
    "trip[\"t\"] = (trip[\"treviews\"] - min(trip[\"treviews\"]))/(max(trip[\"treviews\"] - min(trip[\"treviews\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XLloM-zIQpv8",
   "metadata": {
    "id": "XLloM-zIQpv8"
   },
   "source": [
    "**Get the mean score of TripAdvisor and Google**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "sxhTFI-hI_YI",
   "metadata": {
    "id": "sxhTFI-hI_YI"
   },
   "outputs": [],
   "source": [
    "trip[\"score\"] = 100*((trip[\"g\"]+trip[\"t\"])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CuClScHFQvIc",
   "metadata": {
    "id": "CuClScHFQvIc"
   },
   "source": [
    "**Use the formula $ament_{apartment} = \\sum_{amenity} \\frac{1}{distance_{apartment, amenity}}\\cdot ReviewScore_{amenity}$ to get the index. This index takes into account attractiveness of the place where apartment is, and distance to this from popular amenities** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "cZfD7sA9KhdG",
   "metadata": {
    "id": "cZfD7sA9KhdG"
   },
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "  ament = 0\n",
    "  for indeks, line in trip.iterrows():\n",
    "    ament += line['score']/(geopy.distance.distance(np.array(row[['latitude', 'longitude']]), line['location']).km)\n",
    "  data.at[index, \"ament\"] = ament"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TogbywDJRs6M",
   "metadata": {
    "id": "TogbywDJRs6M"
   },
   "source": [
    "**UNIX time is in seconds. Very large. So I divide to 10^6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "HSZ_L4IgRScD",
   "metadata": {
    "id": "HSZ_L4IgRScD"
   },
   "outputs": [],
   "source": [
    "data[\"first_review_unix\"]=data[\"first_review_unix\"]/(10**6)\n",
    "data[\"last_review_unix\"]=data[\"last_review_unix\"]/(10**6)\n",
    "data[\"ament\"]=data[\"ament\"]/(10**6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YZS7xHXPR26W",
   "metadata": {
    "id": "YZS7xHXPR26W"
   },
   "source": [
    "**Drop unnecessary features. And create lof of the target. Before dropping and did some analysis to check important variables, but I do not show this, omitting for clarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "K8GSIObuZe8i",
   "metadata": {
    "id": "K8GSIObuZe8i"
   },
   "outputs": [],
   "source": [
    "drops = ['source', 'latitude', 'longitude', 'neighbourhood_cleansed','minimum_nights', 'maximum_nights',\n",
    " 'minimum_minimum_nights',\n",
    " 'maximum_minimum_nights',\n",
    " 'minimum_maximum_nights',\n",
    " 'maximum_maximum_nights',\n",
    " 'review_scores_accuracy',\n",
    " 'review_scores_cleanliness',\n",
    " 'review_scores_checkin',\n",
    " 'review_scores_communication',\n",
    " 'review_scores_location',\n",
    " 'review_scores_value', 'number_of_reviews_ltm', 'number_of_reviews_l30d',  'calculated_host_listings_count_entire_homes',\n",
    " 'calculated_host_listings_count_shared_rooms', 'Hot', 'water', 'dryer', 'alarm', 'proptype_Shared room in hostel', 'host_since_unix']\n",
    "df = data.drop(columns=drops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "SsJU7NDKdRuG",
   "metadata": {
    "id": "SsJU7NDKdRuG"
   },
   "outputs": [],
   "source": [
    "df[\"logprice\"]=np.log(df[\"price\"])\n",
    "df = df.replace([-np.inf], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "FEMANJ2ifRT3",
   "metadata": {
    "id": "FEMANJ2ifRT3"
   },
   "outputs": [],
   "source": [
    "lista = [ 'accommodates',\n",
    " 'bedrooms',\n",
    " 'beds',\n",
    " 'last_review_unix',\n",
    " 'bathrooms',\n",
    " 'aval',\n",
    " 'ament']\n",
    "for ind in lista:\n",
    "  df[ind+str(\"_2\")]=df[ind]*df[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j55thYnOSKiu",
   "metadata": {
    "id": "j55thYnOSKiu"
   },
   "source": [
    "**Create holdout sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "-sjV73hHllUv",
   "metadata": {
    "id": "-sjV73hHllUv"
   },
   "outputs": [],
   "source": [
    "out_sample = df.sample(n=300)\n",
    "out_sample_X = out_sample.drop([\"logprice\", \"price\", \"id\", \"scrape_id\"],axis=1)\n",
    "out_sample_y =  out_sample[\"price\"]\n",
    "out_sample_y_log =  out_sample[\"logprice\"]\n",
    "df_learn = df.drop(out_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "93YO2xtwowxo",
   "metadata": {
    "id": "93YO2xtwowxo"
   },
   "outputs": [],
   "source": [
    "df_learn_X = df_learn.drop([\"logprice\", \"price\", \"id\", \"scrape_id\"],axis=1)\n",
    "y = df_learn[\"price\"]\n",
    "log_y = df_learn[\"logprice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "i8xBp_5bpk4n",
   "metadata": {
    "id": "i8xBp_5bpk4n"
   },
   "outputs": [],
   "source": [
    "columns = df_learn_X.columns.to_list()\n",
    "neigh = filter(lambda x: x.startswith('neigh_'), columns)\n",
    "room_type = filter(lambda x: x.startswith('room_type_'), columns)\n",
    "proptype = filter(lambda x: x.startswith('proptype_'), columns)\n",
    "base = list(['host_acceptance_rate',\n",
    " 'host_is_superhost',\n",
    " 'host_listings_count',\n",
    " 'host_identity_verified',\n",
    " 'accommodates',\n",
    " 'bedrooms',\n",
    " 'beds',\n",
    " 'minimum_nights_avg_ntm',\n",
    " 'maximum_nights_avg_ntm',\n",
    " 'number_of_reviews',\n",
    " 'review_scores_rating',\n",
    " 'instant_bookable',\n",
    " 'calculated_host_listings_count',\n",
    " 'calculated_host_listings_count_private_rooms',\n",
    " 'reviews_per_month',\n",
    " 'Hangers',\n",
    " 'Dishes',\n",
    " 'linens',\n",
    " 'Wifi',\n",
    " 'Fire',\n",
    " 'Heating',\n",
    " 'Refrigerator',\n",
    " 'premises',\n",
    " 'Coffee',\n",
    " 'Smoke',\n",
    " 'Iron',\n",
    " 'parking',\n",
    " 'TV',\n",
    " 'Kitchen','first_review_unix',\n",
    " 'last_review_unix',\n",
    " 'bathrooms',\n",
    " 'aval',\n",
    " 'ament'])\n",
    "quad = list([ 'accommodates_2',\n",
    " 'bedrooms_2',\n",
    " 'beds_2',\n",
    " 'last_review_unix_2',\n",
    " 'bathrooms_2',\n",
    " 'aval_2',\n",
    " 'ament_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "3uKtjNOUw_nl",
   "metadata": {
    "id": "3uKtjNOUw_nl"
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5obACg6cSRxE",
   "metadata": {
    "id": "5obACg6cSRxE"
   },
   "source": [
    "**Four specifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "GTB8VzuPzDe3",
   "metadata": {
    "id": "GTB8VzuPzDe3"
   },
   "outputs": [],
   "source": [
    "formula_1 = list(base)\n",
    "formula_2 = list(quad)\n",
    "formula_3 = list(neigh) + list(proptype) + list(room_type)\n",
    "formula_4 = formula_1 + formula_2 +formula_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "l4dzatoWp3_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4dzatoWp3_u",
    "outputId": "ecae2336-d700-4334-b489-5291d3486fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_1': {'RMSE': 962.1637043608615, 'BIC': 108159.24992701387}, 'model_2': {'RMSE': 963.153457435621, 'BIC': 107962.63425991997}, 'model_3': {'RMSE': 966.2213809951669, 'BIC': 108229.58560671254}, 'model_4': {'RMSE': 962.7532842609536, 'BIC': 108501.43496224325}, 'model_1_log': {'RMSE': 0.4479083734089472, 'BIC': 8280.58202927218}, 'model_2_log': {'RMSE': 0.7102543138695565, 'BIC': 14072.32786809198}, 'model_3_log': {'RMSE': 0.636512499918051, 'BIC': 12870.85836572309}, 'model_4_log': {'RMSE': 0.40647466223555845, 'BIC': 7351.173129348038}}\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "#the OLS model\n",
    "\n",
    "def full_ols(dep, formula, name, datas):\n",
    "    model = OLS(datas[dep],datas[formula])\n",
    "    results = model.fit()\n",
    "    metrics[name] = {\"RMSE\":np.sqrt(results.mse_resid) , \"BIC\": results.bic}\n",
    "\n",
    "full_ols('price', formula_1, \"model_1\", df_learn)\n",
    "full_ols('price',formula_2, \"model_2\", df_learn)\n",
    "full_ols('price',formula_3, \"model_3\", df_learn)\n",
    "full_ols('price',formula_4, \"model_4\", df_learn)\n",
    "\n",
    "full_ols('logprice', formula_1, \"model_1_log\", df_learn)\n",
    "full_ols('logprice',formula_2, \"model_2_log\", df_learn)\n",
    "full_ols('logprice',formula_3, \"model_3_log\", df_learn)\n",
    "full_ols('logprice',formula_4, \"model_4_log\", df_learn)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5aOz8BnuyBxr",
   "metadata": {
    "id": "5aOz8BnuyBxr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "qcjj9IKDx_Jh",
   "metadata": {
    "id": "qcjj9IKDx_Jh"
   },
   "outputs": [],
   "source": [
    "k = KFold(n_splits=4, random_state=2023, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "SViY3Onmw-1H",
   "metadata": {
    "id": "SViY3Onmw-1H"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    formula = X_train[formula_1]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_1])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_1_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "ZFx67YYNy1NV",
   "metadata": {
    "id": "ZFx67YYNy1NV"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    formula = X_train[formula_2]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_2])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_2_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "21f8Mo6Dy5QD",
   "metadata": {
    "id": "21f8Mo6Dy5QD"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    formula = X_train[formula_3]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_3])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_3_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "aUwY7WxPy9be",
   "metadata": {
    "id": "aUwY7WxPy9be"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    formula = X_train[formula_4]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_4])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_4_k\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "tXzU1UHv2h_S",
   "metadata": {
    "id": "tXzU1UHv2h_S"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
    "    formula = X_train[formula_1]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_1])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_1_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "KcWuLqwn2pR6",
   "metadata": {
    "id": "KcWuLqwn2pR6"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
    "    formula = X_train[formula_2]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_2])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_2_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "ZsmF_y2a2qyi",
   "metadata": {
    "id": "ZsmF_y2a2qyi"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
    "    formula = X_train[formula_3]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_3])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_3_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "Hc1Hg49-2r5L",
   "metadata": {
    "id": "Hc1Hg49-2r5L"
   },
   "outputs": [],
   "source": [
    "rmse_results = []\n",
    "for train_index, test_index in k.split(df_learn_X):\n",
    "    # Get the training and test data for this fold\n",
    "    X_train, X_test = df_learn_X.iloc[train_index], df_learn_X.iloc[test_index]\n",
    "    y_train, y_test = log_y.iloc[train_index], log_y.iloc[test_index]\n",
    "    formula = X_train[formula_4]\n",
    "    y_train = list(y_train)\n",
    "    model = OLS(y_train,formula)\n",
    "    results = model.fit()\n",
    "    # Predict on the test data\n",
    "    y_pred = results.predict(X_test[formula_4])\n",
    "\n",
    "    # Calculate the RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_results.append(rmse)\n",
    "metrics[\"model_4_k_log\"] = {\"RMSE_1\":rmse_results[0], \"RMSE_2\":rmse_results[1], \"RMSE_3\":rmse_results[2], \"RMSE_4\":rmse_results[3], \"RMSE_average\":np.mean(rmse_results)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "o5SddZd4zTJ9",
   "metadata": {
    "id": "o5SddZd4zTJ9"
   },
   "outputs": [],
   "source": [
    "full_ols('price', formula_1, \"model_out_1\", out_sample)\n",
    "full_ols('price', formula_1, \"model_out_2\", out_sample)\n",
    "full_ols('price', formula_1, \"model_out_3\", out_sample)\n",
    "full_ols('price', formula_4, \"model_out_4\", out_sample)\n",
    "full_ols('logprice', formula_1, \"model_out_1_log\", out_sample)\n",
    "full_ols('logprice', formula_1, \"model_out_2_log\", out_sample)\n",
    "full_ols('logprice', formula_1, \"model_out_3_log\", out_sample)\n",
    "full_ols('logprice', formula_4, \"model_out_4_log\", out_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "KImtL_HqzIP2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KImtL_HqzIP2",
    "outputId": "b9d87cb3-204a-4f85-db7f-de012d9fe25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Model 1     Model 2     Model 3      Model 4\n",
      "RMSE - full sample          962.164     963.153     966.221      962.753\n",
      "BIC - full sample        108159.250  107962.634  108229.586   108501.435\n",
      "RMSE - full sample log        0.448       0.710       0.637        0.406\n",
      "BIC - full sample log      8280.582   14072.328   12870.858     7351.173\n",
      "Fold 1                      264.066     259.283     271.969      273.063\n",
      "Fold 2                  1126194.321     156.485     163.930  1142422.561\n",
      "Fold 3                     1774.156    1775.863    1775.575     1783.805\n",
      "Fold 4                      702.791     695.494     697.673      705.836\n",
      "Average RMSE             282233.833     721.781     727.287   286296.316\n",
      "Fold 1 log                    0.481       0.734       0.658        0.441\n",
      "Fold 2 log                 1325.175       1.012       0.685     1137.202\n",
      "Fold 3 log                    0.449       0.874       0.605        0.638\n",
      "Fold 4 log                    0.443       0.698       0.610        0.413\n",
      "Average RMSE log            331.637       0.829       0.639      284.674\n",
      "Out sample RMSE             134.202     134.202     134.202       91.662\n",
      "Out sample BIC             3948.813    3948.813    3948.813     3903.704\n",
      "Out sample RMSE log           0.413       0.413       0.413        0.344\n",
      "Out sample BIC log          478.802     478.802     478.802      552.017\n"
     ]
    }
   ],
   "source": [
    "table = pd.concat([pd.DataFrame(data=[\n",
    "[metrics[\"model_1\"][\"RMSE\"], metrics[\"model_2\"][\"RMSE\"], metrics[\"model_3\"][\"RMSE\"], metrics[\"model_4\"][\"RMSE\"]],\n",
    "[metrics[\"model_1\"][\"BIC\"], metrics[\"model_2\"][\"BIC\"], metrics[\"model_3\"][\"BIC\"], metrics[\"model_4\"][\"BIC\"]],\n",
    "\n",
    "[metrics[\"model_1_log\"][\"RMSE\"], metrics[\"model_2_log\"][\"RMSE\"], metrics[\"model_3_log\"][\"RMSE\"], metrics[\"model_4_log\"][\"RMSE\"]],\n",
    "[metrics[\"model_1_log\"][\"BIC\"], metrics[\"model_2_log\"][\"BIC\"], metrics[\"model_3_log\"][\"BIC\"], metrics[\"model_4_log\"][\"BIC\"]],\n",
    "\n",
    "[metrics[\"model_1_k\"][\"RMSE_1\"], metrics[\"model_2_k\"][\"RMSE_1\"], metrics[\"model_3_k\"][\"RMSE_1\"], metrics[\"model_4_k\"][\"RMSE_1\"]],\n",
    "[metrics[\"model_1_k\"][\"RMSE_2\"], metrics[\"model_2_k\"][\"RMSE_2\"],metrics[\"model_3_k\"][\"RMSE_2\"],metrics[\"model_4_k\"][\"RMSE_2\"]],\n",
    "[metrics[\"model_1_k\"][\"RMSE_3\"], metrics[\"model_2_k\"][\"RMSE_3\"],metrics[\"model_3_k\"][\"RMSE_3\"],metrics[\"model_4_k\"][\"RMSE_3\"]],\n",
    "[metrics[\"model_1_k\"][\"RMSE_4\"], metrics[\"model_2_k\"][\"RMSE_4\"],metrics[\"model_3_k\"][\"RMSE_4\"],metrics[\"model_4_k\"][\"RMSE_4\"]],\n",
    "[metrics[\"model_1_k\"][\"RMSE_average\"], metrics[\"model_2_k\"][\"RMSE_average\"],metrics[\"model_3_k\"][\"RMSE_average\"],metrics[\"model_4_k\"][\"RMSE_average\"]],\n",
    "\n",
    "[metrics[\"model_1_k_log\"][\"RMSE_1\"], metrics[\"model_2_k_log\"][\"RMSE_1\"], metrics[\"model_3_k_log\"][\"RMSE_1\"], metrics[\"model_4_k_log\"][\"RMSE_1\"]],\n",
    "[metrics[\"model_1_k_log\"][\"RMSE_2\"], metrics[\"model_2_k_log\"][\"RMSE_2\"],metrics[\"model_3_k_log\"][\"RMSE_2\"],metrics[\"model_4_k_log\"][\"RMSE_2\"]],\n",
    "[metrics[\"model_1_k_log\"][\"RMSE_3\"], metrics[\"model_2_k_log\"][\"RMSE_3\"],metrics[\"model_3_k_log\"][\"RMSE_3\"],metrics[\"model_4_k_log\"][\"RMSE_3\"]],\n",
    "[metrics[\"model_1_k_log\"][\"RMSE_4\"], metrics[\"model_2_k_log\"][\"RMSE_4\"],metrics[\"model_3_k_log\"][\"RMSE_4\"],metrics[\"model_4_k_log\"][\"RMSE_4\"]],\n",
    "[metrics[\"model_1_k_log\"][\"RMSE_average\"], metrics[\"model_2_k_log\"][\"RMSE_average\"],metrics[\"model_3_k_log\"][\"RMSE_average\"],metrics[\"model_4_k_log\"][\"RMSE_average\"]],\n",
    "\n",
    "\n",
    "[metrics[\"model_out_1\"][\"RMSE\"], metrics[\"model_out_2\"][\"RMSE\"],metrics[\"model_out_3\"][\"RMSE\"],metrics[\"model_out_4\"][\"RMSE\"]],\n",
    "[metrics[\"model_out_1\"][\"BIC\"], metrics[\"model_out_2\"][\"BIC\"],metrics[\"model_out_3\"][\"BIC\"],metrics[\"model_out_4\"][\"BIC\"]],\n",
    "\n",
    "[metrics[\"model_out_1_log\"][\"RMSE\"], metrics[\"model_out_2_log\"][\"RMSE\"],metrics[\"model_out_3_log\"][\"RMSE\"],metrics[\"model_out_4_log\"][\"RMSE\"]],\n",
    "[metrics[\"model_out_1_log\"][\"BIC\"], metrics[\"model_out_2_log\"][\"BIC\"],metrics[\"model_out_3_log\"][\"BIC\"],metrics[\"model_out_4_log\"][\"BIC\"]]\n",
    "\n",
    " ], columns=[\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"]).rename({0: \"RMSE - full sample\", 1: \"BIC - full sample\", \n",
    "                                                                  2: \"RMSE - full sample log\", 3: \"BIC - full sample log\", \n",
    "                                                                  4:\"Fold 1\", 5:\"Fold 2\", 6:\"Fold 3\", 7:\"Fold 4\", 8:\"Average RMSE\", \n",
    "                                                                  \n",
    "                                                                  9:\"Fold 1 log\", 10:\"Fold 2 log\", 11:\"Fold 3 log\", 12:\"Fold 4 log\", 13:\"Average RMSE log\", \n",
    "                                                                  14:\"Out sample RMSE\", 15:\"Out sample BIC\",\n",
    "                                                                   16:\"Out sample RMSE log\", 17:\"Out sample BIC log\"\n",
    "                                                                   }, axis=0),\n",
    "    ]).round(3)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YJD1FjseSXuf",
   "metadata": {
    "id": "YJD1FjseSXuf"
   },
   "source": [
    "**By RMSE on full sample Model 1 is the best, but considering BIC Model 2 is the best one. On log scale Model 4 is the best one, with BIC also. CV shows that Model 2 and Model 3 are the best ones, in the log scale target also.Holdout results differ.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "rjDNgBGa5AuE",
   "metadata": {
    "id": "rjDNgBGa5AuE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "qZsCJYSt0fLb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZsCJYSt0fLb",
    "outputId": "b01a4ac4-f429-41ef-9fd1-c52517ac48d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    3000\n",
       "2     0.01\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_1], y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "sQlfMwLIHBzM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQlfMwLIHBzM",
    "outputId": "9206e154-a7d6-4a34-d990-f37cfe09a201"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0001\n",
       "1     0.001\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_2], y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "vxjpGZSvHEMk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxjpGZSvHEMk",
    "outputId": "8a159cbb-e607-4b36-c5b2-83eb5b3718bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    1.0\n",
       "11    0.8\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_3], y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "cJh5rUhmHJHa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJh5rUhmHJHa",
    "outputId": "7ea3f4b7-d5cc-41a3-9d58-40db4416988e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    3000\n",
       "28    2000\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_4], y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "UhPlZH2ZHMm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhPlZH2ZHMm7",
    "outputId": "d11342d8-f533-4ff2-bb0b-3580d514074b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    3000\n",
       "28    2000\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_1], log_y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "E26BeulDHRMk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E26BeulDHRMk",
    "outputId": "a9c155bf-3798-41d1-9aa9-fc2b711c053e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0001\n",
       "1     0.001\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_2], log_y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "8hvrp6A6HUJV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hvrp6A6HUJV",
    "outputId": "47752422-01cf-4a2f-c9a8-c931757925aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.001\n",
       "0    0.0001\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_3], log_y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "u7B29aKZHXfj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7B29aKZHXfj",
    "outputId": "82f387b3-217a-4579-f26a-6c0503e21731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    3000\n",
       "28    2000\n",
       "Name: param_alpha, dtype: object"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000, 2000, 3000]}\n",
    "folds = 4\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = 4)            \n",
    "\n",
    "model_cv.fit(df_learn_X[formula_4], log_y) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "cv_results.sort_values(by='mean_test_score', ascending=False)[\"param_alpha\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "niYgAU3AFrFU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niYgAU3AFrFU",
    "outputId": "de6d747f-d31a-42f3-d9bd-94ca98c8b5d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.0293757579665\n",
      "150.4923232905115\n",
      "154.14600700112607\n",
      "160.70124533576086\n"
     ]
    }
   ],
   "source": [
    "formulas = [formula_1, formula_2, formula_3, formula_4]\n",
    "y_alpha = [0.01, 0.001, 0.8, 2000]\n",
    "ylog_alpha = [2000, 0.001,0.001,2000]\n",
    "n=0\n",
    "for i in y_alpha:\n",
    "  lasso = Lasso(alpha=i)\n",
    "  lasso.fit(df_learn_X[formulas[n]],  y)\n",
    "  y_pred = lasso.predict(out_sample_X[formulas[n]])\n",
    "  n += 1\n",
    "  print(np.sqrt(metrics.mean_squared_error(out_sample_y,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "KWBDZGJgI7O6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWBDZGJgI7O6",
    "outputId": "b7cf0e4a-046b-4ef5-f964-e0a911579d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5576329220871954\n",
      "0.5519331212161148\n",
      "0.4629085168955835\n",
      "0.5567455219323949\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for i in ylog_alpha:\n",
    "  lasso = Lasso(alpha=i)\n",
    "  lasso.fit(df_learn_X[formulas[n]],  log_y)\n",
    "  y_pred = lasso.predict(out_sample_X[formulas[n]])\n",
    "  n += 1\n",
    "  print(np.sqrt(metrics.mean_squared_error(out_sample_y_log,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "wQwSZlArLMeD",
   "metadata": {
    "id": "wQwSZlArLMeD"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "0MUjSMK9J4M0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MUjSMK9J4M0",
    "outputId": "34e5c41d-9146-4c91-eafe-4c83cbdb9a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.51394744427928\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_1],y)\n",
    "\n",
    "# print(xgb_grid.best_score_)\n",
    "# print(xgb_grid.best_params_)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "8WQyzC4uO0V5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WQyzC4uO0V5",
    "outputId": "aa88f183-a0e2-4c3a-b85a-fcf81ff40ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.65707500696715\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_2],y)\n",
    "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "DO-T3RVAO2j6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DO-T3RVAO2j6",
    "outputId": "6aab2319-8dbd-4a1b-86ea-ab673c37eda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.64360955690316\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_3],y)\n",
    "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_3]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "nG7EOVutO5Sp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nG7EOVutO5Sp",
    "outputId": "c3d631c9-2098-4e19-e2d5-88cbbb7d75f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.02371153809318\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_4],y)\n",
    "print(np.sqrt(mean_squared_error(out_sample_y, xgb_grid.predict(out_sample_X[formula_4]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "tfOwrb7bO65x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfOwrb7bO65x",
    "outputId": "f43329da-cc1d-40f5-fe6d-e3799522cdd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32226302998271317\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_1],log_y)\n",
    "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_grid.predict(out_sample_X[formula_1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "jv_nVA6iO9-5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jv_nVA6iO9-5",
    "outputId": "c32cdcc5-dd5a-4940-9e04-6708830254e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3730223366657394\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_2],log_y)\n",
    "xgb_l_4 = xgb_grid.predict(out_sample_X[formula_4])\n",
    "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_l_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "I3N74ZOoPApw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3N74ZOoPApw",
    "outputId": "b886e320-30d0-4cb3-a085-c2eca8dfe477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44644560390678417\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_3],log_y)\n",
    "xgb_l_3 = xgb_grid.predict(out_sample_X[formula_3])\n",
    "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_l_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "oOT1iHzVPDSI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOT1iHzVPDSI",
    "outputId": "e6c2a733-ab28-4e8b-c268-84fa688528dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3172774335626686\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(seed = 2023)\n",
    "parameters = {'nthread':[-1],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, .07],\n",
    "              'max_depth': [5, 10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.85],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = -1,\n",
    "                        scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "xgb_grid.fit(df_learn_X[formula_4],log_y)\n",
    "xgb_l_4 = xgb_grid.predict(out_sample_X[formula_4])\n",
    "print(np.sqrt(mean_squared_error(out_sample_y_log, xgb_l_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "wzSQ-W_zhuWZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzSQ-W_zhuWZ",
    "outputId": "e839cb06-79c1-41c8-9c60-d6e1486820e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Model 1     Model 2     Model 3  \\\n",
      "RMSE: Out sample OLS price         134.201855  134.201855  134.201855   \n",
      "RMSE: Out sample OLS log price       0.413124    0.413124    0.413124   \n",
      "RMSE: Out Sample: Lasso Price             148       150.5       154.2   \n",
      "RMSE: Out Sample: Lasso Log Price       0.558       0.551         046   \n",
      "RMSE: Out Sample: XGB Price            127.51      139.65      180.64   \n",
      "RMSE: Out Sample: XGB Log Price         0.322       0.373        0.44   \n",
      "\n",
      "                                     Model 4  \n",
      "RMSE: Out sample OLS price         91.661515  \n",
      "RMSE: Out sample OLS log price      0.343681  \n",
      "RMSE: Out Sample: Lasso Price          160.7  \n",
      "RMSE: Out Sample: Lasso Log Price      0.557  \n",
      "RMSE: Out Sample: XGB Price              118  \n",
      "RMSE: Out Sample: XGB Log Price        0.317  \n"
     ]
    }
   ],
   "source": [
    "table = pd.concat([pd.DataFrame(data=[\n",
    "[metrics[\"model_out_1\"][\"RMSE\"], metrics[\"model_out_2\"][\"RMSE\"],metrics[\"model_out_3\"][\"RMSE\"],metrics[\"model_out_4\"][\"RMSE\"]],\n",
    "\n",
    "[metrics[\"model_out_1_log\"][\"RMSE\"], metrics[\"model_out_2_log\"][\"RMSE\"],metrics[\"model_out_3_log\"][\"RMSE\"],metrics[\"model_out_4_log\"][\"RMSE\"]],\n",
    "[\"148\", \"150.5\", \"154.2\", \"160.7\" ],\n",
    "[\"0.558\", \"0.551\", \"046\", \"0.557\" ],\n",
    "[\"127.51\", \"139.65\", \"180.64\", \"118\" ],\n",
    "[\"0.322\", \"0.373\", \"0.44\", \"0.317\" ]\n",
    "\n",
    " ], columns=[\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"]).rename({ 0:\"RMSE: Out sample OLS price\", \n",
    "                                                                   1:\"RMSE: Out sample OLS log price\", \n",
    "                                                                   2: \"RMSE: Out Sample: Lasso Price\",\n",
    "                                                                   3: \"RMSE: Out Sample: Lasso Log Price\", \n",
    "                                                                   4: \"RMSE: Out Sample: XGB Price\", \n",
    "                                                                   5: \"RMSE: Out Sample: XGB Log Price\", \n",
    "                                                                   }, axis=0),\n",
    "    ]).round(3)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vA9lpLRIjGAf",
   "metadata": {
    "id": "vA9lpLRIjGAf"
   },
   "source": [
    "**In OLS Model 4 wins. In Lasso Model 1 for price, and Model 4 for log price. For XGB also Model 4 wins. Seemingly, althoug there is evidence of overfitting in OLS Model 4, because of many features it did best in hold out data as other types of models**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
